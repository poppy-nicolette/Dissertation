DOI: 10.1007/978-3-031-55642-5_1
Title: 大規模言語モデルの概要 An Overview on Large Language Models
Abstract: 大規模言語モデル (LLM) の進歩によって推進された生成人工知能 (AI) は、さまざまなソフトウェア エンジニアリング (SE) タスクやそれ以外のタスクでも顕著な能力を発揮してきました。この発展は、この分野の研究研究に影響を与えました。この章では、LLM の概要を説明し、関連する背景概念を掘り下げながら、LLM 研究の最前線の高度な技術を探ります。トレーニング、微調整、およびコンテキスト内学習の概念について説明することに加えて、さまざまな LLM アーキテクチャを確認します。また、LLM と拡張 LLM に対するさまざまな適応アプローチについても説明しました。さらに、LLM 研究の評価を掘り下げ、この文脈におけるベンチマーク データセットと関連ツールを紹介します。この章の最後では、SE タスクに LLM を活用する際の制限について説明します。 Generative artificial intelligence (AI), propelled by the advancements in large language models (LLMs), has exhibited remarkable capabilities in various software engineering (SE) tasks and beyond. This development has influenced the research studies in this domain. This chapter offers an overview of LLMs, delving into relevant background concepts while exploring advanced techniques at the forefront of LLM research. We review various LLM architectures, in addition to discussing the concepts of training, fine-tuning, and in-context learning. We also discussed different adaptation approaches to LLMs and augmented LLMs. Furthermore, we delve into the evaluation of LLM research, introducing benchmark datasets and relevant tools in this context. The chapter concludes by exploring limitations in leveraging LLMs for SE tasks.

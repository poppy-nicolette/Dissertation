{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Part 2:The shared corpus study\n",
    "author: <span style=\"color:magenta\">Poppy Riddle</span><br>\n",
    "date: Mar 31, 2025\n",
    "\n",
    "## Data collection\n",
    "- [ ] create sample collection from Crossref from part 1\n",
    "- [ ] create shared corpus with works also found in OpenAlex matched on DOI\n",
    "    - take DOI from Crossref sample df_collated2 export\n",
    "    - send API call to OpenAlex for single work to select relevant elements or all and then refine down to elements needed for analysis\n",
    "        - example API: https://api.openalex.org/works?filter=doi:10.7717/peerj.4375&select=doi,title,id,publication_year,language,abstract_inverted_index\n",
    "    - reconstruct abstract from inverted \n",
    "        - [x] reconstruction code\n",
    "- [ ] Crossref schema and OpenAlex schema comparison\n",
    "    - Crossref schema: https://data.crossref.org/reports/help/schema_doc/5.3.1/index.html\n",
    "    - OpenAlex schema: https://docs.openalex.org/api-entities/works/work-object\n",
    "    - create diagram of this map\n",
    "    - create dictionary to build later\n",
    "- [ ] create mapping of metadata element from Crossref and its respective element in OpenAlex\n",
    "    - cr_title -> openalex_title\n",
    "    - cr_citedby_count -> openalex_citedby\n",
    "    - etc\n",
    "- [ ] quantify differences\n",
    "    - [ ] exact match for numerical or absolute str values\n",
    "        - cited_by\n",
    "        - language\n",
    "        - URL\n",
    "        - doc_type\n",
    "        - license \n",
    "    - [ ] Levenshtein ratio for str values that can accept some variation without changing meaning: https://rapidfuzz.github.io/Levenshtein/\n",
    "        - title (may want to use Levenshtein.seqratio())\n",
    "        - abstract (may want to use Levenshtein.seqratio())\n",
    "- [ ] identify changes from publisher deposited data (Crossref) to OpenAlex\n",
    "    - DOI, title, abstract, license type, license, cited-by, language, and document type.\n",
    "- [ ] identify which error types occur: incorrect values, missing info, inconsistent values\n",
    "- [ ] visualize: other pubs have used Sankey diagram to show change - other ways to do this? Or improve upon the Sankey approach?\n",
    "\n",
    "## helpers:\n",
    "### Python\n",
    "- the Pyalex library: https://pypi.org/project/pyalex/#get-abstract\n",
    "- how to uninvert: https://stackoverflow.com/questions/72093757/running-python-loop-to-iterate-and-undo-inverted-index\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import pickle\n",
    "import json\n",
    "from colorama import Fore,Back,Style\n",
    "import time\n",
    "import csv\n",
    "import xmltodict #probably not needed here\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'level_0', 'index', 'doi', 'doi_type', 'title', 'abstract', 'citedby_count', 'doi_url', 'abstract_keys_count', 'abstract_type', 'license_x',\n",
      "       'license_y'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>doi</th>\n",
       "      <th>doi_type</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>citedby_count</th>\n",
       "      <th>doi_url</th>\n",
       "      <th>abstract_keys_count</th>\n",
       "      <th>abstract_type</th>\n",
       "      <th>license_x</th>\n",
       "      <th>license_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.3390/su152215683</td>\n",
       "      <td>journal_article</td>\n",
       "      <td>Underpinning Quality Assurance: Identifying Co...</td>\n",
       "      <td>{'language': None, 'text': 'The Internet of Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.mdpi.com/2071-1050/15/22/15683</td>\n",
       "      <td>2</td>\n",
       "      <td>dict</td>\n",
       "      <td>https://creativecommons.org/licenses/by/4.0/</td>\n",
       "      <td>https://creativecommons.org/licenses/by/4.0/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                  doi         doi_type  ... abstract_type                                     license_x                                     license_y\n",
       "0      0  10.3390/su152215683  journal_article  ...          dict  https://creativecommons.org/licenses/by/4.0/  https://creativecommons.org/licenses/by/4.0/\n",
       "\n",
       "[1 rows x 11 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get samples from part 1\n",
    "file = \"data/part_1_sample.txt\"\n",
    "df = pd.read_csv(file, sep='\\t', encoding='utf-8', header=0)\n",
    "print(df.columns)\n",
    "df.drop(['Unnamed: 0','level_0'], axis=1, inplace=True)\n",
    "df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct abtract - from https://stackoverflow.com/questions/72093757/running-python-loop-to-iterate-and-undo-inverted-index\n",
    "\n",
    "\n",
    "def reconstruct_abstract(abstract:dict)-> str:\n",
    "\n",
    "    \"\"\"\n",
    "    This takes a dictionary of the inverted abstract\n",
    "    and returns a string of the reconstructed abstract.\n",
    "\n",
    "    Args:\n",
    "    abstract should be in the form of a dictionary. \n",
    "    Example:\n",
    "    abstract_inverted_index = {\n",
    "    'Despite':[0],\n",
    "    'growing':[1],\n",
    "   'interest': [2],\n",
    "    'in': [3],\n",
    "    'Open': [4],\n",
    "    'Access': [5],\n",
    "    '...': [6]\n",
    "\n",
    "    Returns:\n",
    "    String \n",
    "    \"\"\"\n",
    "\n",
    "    # Create a list of (word, index) pairs\n",
    "    word_index = []\n",
    "    for k, v in abstract.items():\n",
    "        for index in v:\n",
    "            word_index.append([k, index])\n",
    "\n",
    "    #print(word_index) # uncomment to see the sublists\n",
    "    # Sort the list based on index\n",
    "    word_index = sorted(word_index, key=lambda x: x[1]) # this sorts based on the second item in the sublist\n",
    "\n",
    "    # Join the words with a space\n",
    "    abstract = ' '.join([word for word, index in word_index])\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect OpenAlex data\n",
    "\n",
    "# send call to OpenAelx API\n",
    "def get_openalex_data(doi:str)->dict:\n",
    "    \"\"\"\n",
    "    Arg: takes a DOI as a string without the resolver.\n",
    "    Return: A dictionary of values.\n",
    "\n",
    "    Note: oa_abstract is reconstructed from the function reconstruct_abstract()\n",
    "    \"\"\"\n",
    "    URL = f\"https://api.openalex.org/works?filter=doi:{doi}&select=doi,title,id,type,type_crossref,language,abstract_inverted_index,cited_by_count,is_paratext,primary_location\"\n",
    "    result = requests.get(URL)\n",
    "    \n",
    "    if result.status_code == 200:\n",
    "        data = result.json()\n",
    "\n",
    "        #parse json data into each element:\n",
    "        oa_doi = data['results'][0]['doi'].lstrip('https://doi.org/')\n",
    "        oa_title = data['results'][0]['title']\n",
    "        oa_id = data['results'][0]['id']\n",
    "        oa_type = data['results'][0]['type']\n",
    "        oa_type_crossref = data['results'][0]['type_crossref']\n",
    "        oa_language = data['results'][0]['language']\n",
    "        oa_abstract_inverted_index = data['results'][0]['abstract_inverted_index']\n",
    "        oa_cited_by_count = data['results'][0]['cited_by_count']\n",
    "        oa_is_paratext = data['results'][0]['is_paratext']\n",
    "        oa_primary_location_pdf_url = data['results'][0]['primary_location']['pdf_url']\n",
    "        oa_license = data['results'][0]['primary_location']['license']\n",
    "        oa_version = data['results'][0]['primary_location']['version']\n",
    "\n",
    "    oa_abstract = reconstruct_abstract(oa_abstract_inverted_index)\n",
    "\n",
    "    return {'oa_doi': oa_doi,\n",
    "            'oa_title':oa_title,\n",
    "            'oa_id':oa_id,\n",
    "            'oa_type':oa_type,\n",
    "            'oa_type_crossref':oa_type_crossref,\n",
    "            'oa_language':oa_language,\n",
    "            'oa_abstract_inverted_index':oa_abstract_inverted_index,\n",
    "            'oa_abstract':oa_abstract,\n",
    "            'oa_cited_by_count':oa_cited_by_count,\n",
    "            'oa_is_paratext':oa_is_paratext,\n",
    "            'oa_primary_location_pdf_url':oa_primary_location_pdf_url,\n",
    "            'oa_license':oa_license,\n",
    "            'oa_version':oa_version\n",
    "            }\n",
    "\n",
    "    time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oa_doi': '10.3390/su152215683',\n",
       " 'oa_title': 'Underpinning Quality Assurance: Identifying Core Testing Strategies for Multiple Layers of Internet-of-Things-Based Applications',\n",
       " 'oa_id': 'https://openalex.org/W4388446692',\n",
       " 'oa_type': 'article',\n",
       " 'oa_type_crossref': 'journal-article',\n",
       " 'oa_language': 'en',\n",
       " 'oa_abstract_inverted_index': {'The': [0],\n",
       "  'Internet': [1],\n",
       "  'of': [2, 10, 26, 48, 75, 84, 142, 153, 166],\n",
       "  'Things': [3],\n",
       "  '(IoT)': [4],\n",
       "  'constitutes': [5],\n",
       "  'a': [6, 24, 85, 94, 100, 140],\n",
       "  'digitally': [7],\n",
       "  'integrated': [8],\n",
       "  'network': [9],\n",
       "  'intelligent': [11],\n",
       "  'devices': [12],\n",
       "  'equipped': [13],\n",
       "  'with': [14],\n",
       "  'sensors,': [15],\n",
       "  'software,': [16],\n",
       "  'and': [17, 51, 164],\n",
       "  'communication': [18],\n",
       "  'capabilities,': [19],\n",
       "  'facilitating': [20],\n",
       "  'data': [21],\n",
       "  'exchange': [22],\n",
       "  'among': [23],\n",
       "  'multitude': [25],\n",
       "  'digital': [27],\n",
       "  'systems': [28],\n",
       "  'via': [29],\n",
       "  'the': [30, 37, 82, 119, 137, 150, 154, 162],\n",
       "  'Internet.': [31],\n",
       "  'Despite': [32],\n",
       "  'its': [33],\n",
       "  'pivotal': [34],\n",
       "  'role': [35],\n",
       "  'in': [36, 46, 78, 109, 133],\n",
       "  'software': [38, 44, 92],\n",
       "  'development': [39],\n",
       "  'life-cycle': [40],\n",
       "  '(SDLC)': [41],\n",
       "  'for': [42, 72, 89, 125],\n",
       "  'ensuring': [43],\n",
       "  'quality': [45, 106, 127],\n",
       "  'terms': [47],\n",
       "  'both': [49],\n",
       "  'functional': [50],\n",
       "  'non-functional': [52],\n",
       "  'aspects,': [53],\n",
       "  'testing': [54, 68, 112, 116],\n",
       "  'within': [55, 118, 149],\n",
       "  'this': [56],\n",
       "  'intricate': [57],\n",
       "  'software–hardware': [58],\n",
       "  'ecosystem': [59],\n",
       "  'has': [60],\n",
       "  'been': [61],\n",
       "  'somewhat': [62],\n",
       "  'overlooked.': [63],\n",
       "  'To': [64],\n",
       "  'address': [65],\n",
       "  'this,': [66],\n",
       "  'various': [67],\n",
       "  'techniques': [69],\n",
       "  'are': [70],\n",
       "  'applied': [71],\n",
       "  'real-time': [73, 134],\n",
       "  'minimization': [74],\n",
       "  'failure': [76, 131],\n",
       "  'rates': [77, 132],\n",
       "  'IoT': [79, 91],\n",
       "  'applications.': [80, 168],\n",
       "  'However,': [81],\n",
       "  'execution': [83],\n",
       "  'comprehensive': [86, 157],\n",
       "  'test': [87],\n",
       "  'suite': [88],\n",
       "  'specific': [90],\n",
       "  'remains': [93],\n",
       "  'complex': [95],\n",
       "  'undertaking.': [96],\n",
       "  'This': [97, 121, 156],\n",
       "  'paper': [98, 138],\n",
       "  'proposes': [99],\n",
       "  'holistic': [101],\n",
       "  'framework': [102, 152],\n",
       "  'aimed': [103],\n",
       "  'at': [104],\n",
       "  'aiding': [105],\n",
       "  'assurance': [107],\n",
       "  'engineers': [108],\n",
       "  'delineating': [110],\n",
       "  'essential': [111],\n",
       "  'methods': [113],\n",
       "  'across': [114],\n",
       "  'different': [115],\n",
       "  'levels': [117],\n",
       "  'IoT.': [120, 155],\n",
       "  'delineation': [122],\n",
       "  'is': [123],\n",
       "  'crucial': [124],\n",
       "  'effective': [126],\n",
       "  'assurance,': [128],\n",
       "  'ultimately': [129],\n",
       "  'reducing': [130],\n",
       "  'scenarios.': [135],\n",
       "  'Furthermore,': [136],\n",
       "  'offers': [139],\n",
       "  'mapping': [141],\n",
       "  'these': [143],\n",
       "  'identified': [144],\n",
       "  'tests': [145],\n",
       "  'to': [146, 160],\n",
       "  'each': [147],\n",
       "  'layer': [148],\n",
       "  'layered': [151],\n",
       "  'approach': [158],\n",
       "  'seeks': [159],\n",
       "  'enhance': [161],\n",
       "  'reliability': [163],\n",
       "  'performance': [165],\n",
       "  'IoT-based': [167]},\n",
       " 'oa_abstract': 'The Internet of Things (IoT) constitutes a digitally integrated network of intelligent devices equipped with sensors, software, and communication capabilities, facilitating data exchange among a multitude of digital systems via the Internet. Despite its pivotal role in the software development life-cycle (SDLC) for ensuring software quality in terms of both functional and non-functional aspects, testing within this intricate software–hardware ecosystem has been somewhat overlooked. To address this, various testing techniques are applied for real-time minimization of failure rates in IoT applications. However, the execution of a comprehensive test suite for specific IoT software remains a complex undertaking. This paper proposes a holistic framework aimed at aiding quality assurance engineers in delineating essential testing methods across different testing levels within the IoT. This delineation is crucial for effective quality assurance, ultimately reducing failure rates in real-time scenarios. Furthermore, the paper offers a mapping of these identified tests to each layer within the layered framework of the IoT. This comprehensive approach seeks to enhance the reliability and performance of IoT-based applications.',\n",
       " 'oa_cited_by_count': 0,\n",
       " 'oa_is_paratext': False,\n",
       " 'oa_primary_location_pdf_url': 'https://www.mdpi.com/2071-1050/15/22/15683/pdf?version=1699345258',\n",
       " 'oa_license': None,\n",
       " 'oa_version': 'publishedVersion'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on single doi\n",
    "# 10.3390/su152215683\n",
    "get_openalex_data(\"10.3390/su152215683\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[35m██████████\u001b[0m| 20/20 [00:04<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['\u001b[35moa_doi', '\u001b[35moa_title', '\u001b[35moa_id', '\u001b[35moa_type', '\u001b[35moa_type_crossref', '\u001b[35moa_language', '\u001b[35moa_abstract_inverted_index',\n",
      "       '\u001b[35moa_abstract', '\u001b[35moa_cited_by_count', '\u001b[35moa_is_paratext', '\u001b[35moa_primary_location_pdf_url', '\u001b[35moa_license', '\u001b[35moa_version'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oa_doi</th>\n",
       "      <th>oa_title</th>\n",
       "      <th>oa_id</th>\n",
       "      <th>oa_type</th>\n",
       "      <th>oa_type_crossref</th>\n",
       "      <th>oa_language</th>\n",
       "      <th>oa_abstract_inverted_index</th>\n",
       "      <th>oa_abstract</th>\n",
       "      <th>oa_cited_by_count</th>\n",
       "      <th>oa_is_paratext</th>\n",
       "      <th>oa_primary_location_pdf_url</th>\n",
       "      <th>oa_license</th>\n",
       "      <th>oa_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.3390/su152215683</td>\n",
       "      <td>Underpinning Quality Assurance: Identifying Co...</td>\n",
       "      <td>https://openalex.org/W4388446692</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>en</td>\n",
       "      <td>{'The': [0], 'Internet': [1], 'of': [2, 10, 26...</td>\n",
       "      <td>The Internet of Things (IoT) constitutes a dig...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.mdpi.com/2071-1050/15/22/15683/pdf...</td>\n",
       "      <td>None</td>\n",
       "      <td>publishedVersion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.25139/jkp.v6i6.5294</td>\n",
       "      <td>Proses Pengambilan Keputusan Adopsi Inovasi Ap...</td>\n",
       "      <td>https://openalex.org/W4362648852</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>id</td>\n",
       "      <td>{'This': [0], 'study': [1], 'aims': [2], 'to':...</td>\n",
       "      <td>This study aims to determine how the process o...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>https://ejournal.unitomo.ac.id/index.php/jkp/a...</td>\n",
       "      <td>None</td>\n",
       "      <td>publishedVersion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   oa_doi                                           oa_title  ... oa_license        oa_version\n",
       "0     10.3390/su152215683  Underpinning Quality Assurance: Identifying Co...  ...       None  publishedVersion\n",
       "1  10.25139/jkp.v6i6.5294  Proses Pengambilan Keputusan Adopsi Inovasi Ap...  ...       None  publishedVersion\n",
       "\n",
       "[2 rows x 13 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "openalex_data = []\n",
    "\n",
    "for doi in tqdm(df['doi'],colour=\"MAGENTA\"):\n",
    "    result = get_openalex_data(doi)\n",
    "    openalex_data.append(result)\n",
    "\n",
    "df_openalex = pd.DataFrame(openalex_data)\n",
    "\n",
    "print(Fore.MAGENTA + df_openalex.columns)\n",
    "\n",
    "df_openalex.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mpercent matched from Crossref: 100.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>match_on_doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1039/d3nr03946c</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1051/e3sconf/202448001017</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1063/5.0208102</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1088/1674-1056/ac16cd</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1088/1755-1315/899/1/012022</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.1093/eurheartjsupp/suac121.504</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.1177/1357034x231201950</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.18203/2320-6012.ijrms20230875</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.19181/socjour.2021.27.3.8426</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.24191/mij.v1i1.14172</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.24911/ijmdc.51-1696257618</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.25139/jkp.v6i6.5294</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.30574/wjarr.2024.21.1.0037</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.3390/h14020028</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.3390/nu13082520</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.3390/plants12223844</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.3390/su152215683</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.46502/issn.1856-7576/2022.16.03.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.5913/pala.13.2020.a012</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.59966/ekalaya.v1i3.202</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     doi  match_on_doi\n",
       "0                     10.1039/d3nr03946c          True\n",
       "1           10.1051/e3sconf/202448001017          True\n",
       "2                      10.1063/5.0208102          True\n",
       "3               10.1088/1674-1056/ac16cd          True\n",
       "4         10.1088/1755-1315/899/1/012022          True\n",
       "5      10.1093/eurheartjsupp/suac121.504          True\n",
       "6              10.1177/1357034x231201950          True\n",
       "7       10.18203/2320-6012.ijrms20230875          True\n",
       "8        10.19181/socjour.2021.27.3.8426          True\n",
       "9                10.24191/mij.v1i1.14172          True\n",
       "10          10.24911/ijmdc.51-1696257618          True\n",
       "11                10.25139/jkp.v6i6.5294          True\n",
       "12         10.30574/wjarr.2024.21.1.0037          True\n",
       "13                     10.3390/h14020028          True\n",
       "14                    10.3390/nu13082520          True\n",
       "15                10.3390/plants12223844          True\n",
       "16                   10.3390/su152215683          True\n",
       "17  10.46502/issn.1856-7576/2022.16.03.4          True\n",
       "18             10.5913/pala.13.2020.a012          True\n",
       "19             10.59966/ekalaya.v1i3.202          True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare Crossref df and oa df match on DOI\n",
    "# new df with a boolean value if they share: doi, match_on_doi,...\n",
    "# this will expand out for other boolean values\n",
    "\n",
    "# match on df['doi'] and df_openalex['oa_doi']\n",
    "match_on_doi_df = df[['doi']].merge(df_openalex[['oa_doi']], left_on='doi', right_on='oa_doi', how='outer')\n",
    "\n",
    "match_on_doi_df['match_on_doi'] = match_on_doi_df['doi'] == match_on_doi_df['oa_doi']\n",
    "\n",
    "match_on_doi_df = match_on_doi_df.drop(['oa_doi'], axis=1)\n",
    "\n",
    "print(Fore.CYAN + f\"percent matched from Crossref: {len(match_on_doi_df)/len(df)*100:.1f}%\")\n",
    "\n",
    "match_on_doi_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Crossref schema and OpenAlex schema comparison\n",
    "    - Crossref schema: https://data.crossref.org/reports/help/schema_doc/5.3.1/index.html\n",
    "    - OpenAlex schema: https://docs.openalex.org/api-entities/works/work-object\n",
    "    - create diagram of this map\n",
    "    - create dictionary to build later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] create mapping of metadata element from Crossref and its respective element in OpenAlex\n",
    "    - cr_title -> openalex_title\n",
    "    - cr_citedby_count -> openalex_citedby\n",
    "    - etc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] quantify differences\n",
    "    - [ ] exact match for numerical or absolute str values\n",
    "        - cited_by\n",
    "        - language\n",
    "        - URL\n",
    "        - doc_type\n",
    "        - license \n",
    "    - [ ] Levenshtein ratio for str values that can accept some variation without changing meaning: https://rapidfuzz.github.io/Levenshtein/\n",
    "        - title (may want to use Levenshtein.seqratio())\n",
    "        - abstract (may want to use Levenshtein.seqratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overall changes\n",
    "- [ ] identify changes from publisher deposited data (Crossref) to OpenAlex\n",
    "    - DOI, title, abstract, license type, license, cited-by, language, and document type -> 0 for missing, 1 for present\n",
    "    - create table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOI specific metadata\n",
    "- [ ] Change in DOI URL from Crossref to OpenAlex, (0,1)\n",
    "- [ ] count of those that have https vs http (as an indicator of link rot)\n",
    "- [ ] count of HTTP status code on all URLs\n",
    "- [ ] count of those not working (such as 400)\n",
    "- [ ] create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### publication type\n",
    "- [ ] count of each type\n",
    "- [ ] change from Crossref to Openalex, 0,1?\n",
    "- [ ] % distribution \n",
    "- [ ] maybe a good place for a sankey diagram showing changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### title\n",
    "- [ ] change between Crossref and OpenAlex 0,1?\n",
    "- [ ] count of tokens in each\n",
    "- [ ] count of stopwords\n",
    "- [ ] count of punctuation\n",
    "- [ ] count of special char, formating char\n",
    "- [ ] count of numerals\n",
    "- [ ] count of tags or other non-text elements\n",
    "- [ ] visualize distribution of these across both databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abstract\n",
    "- [ ] change between Crossref and OpenAlex?\n",
    "- [ ] count of tokens in each\n",
    "- [ ] count of stopwords\n",
    "- [ ] count of punctuation\n",
    "- [ ] count of special char, formating char\n",
    "- [ ] count of numerals\n",
    "- [ ] count of tags or other non-text elements\n",
    "- [ ] visualize distribution of these across both databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cited by count\n",
    "- [ ] std dev of differences between two samples\n",
    "- [ ] n with change\n",
    "- [ ] % affected\n",
    "- [ ] visualize to see if one database favors more than the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### license\n",
    "- [ ] change between Crossref and OpenAlex?\n",
    "- [ ] count of types for each\n",
    "- [ ] count of those with licenses vs without\n",
    "- [ ] % of those with \n",
    "- [ ] count of common or proprietary licenses\n",
    "- [ ] visualization of distribution of license types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### languages\n",
    "- [ ] change between Crossref and OpenAlex\n",
    "- [ ] count of types\n",
    "- [ ] % declared in abstract\n",
    "    - found in XML API\n",
    "- [ ] % declared in journal title level\n",
    "    - found in REST API\n",
    "- [ ] visualization of distribution of language types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative Analysis\n",
    "\n",
    "### License\n",
    "IF there are differences, an examination of changes between two sources. This may require a subset based on filtering from above. \n",
    "- [ ] comparison of license in each source\n",
    "- [ ] apply an error classification: incorrect, missing, inconsistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### title and abstract\n",
    "- [ ] filter df from above for those with differences \n",
    "    - [ ] use subset if needed due to quantity\n",
    "- [ ] compare title from each source based on Levenshtein seqratio\n",
    "- [ ] compare abstract from each source based on Levenshtein seqratio\n",
    "- [ ] apply classification\n",
    "- [ ] identify error types \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

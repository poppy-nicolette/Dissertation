{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Part 2:The shared corpus study\n",
    "author: <span style=\"color:magenta\">Poppy Riddle</span><br>\n",
    "date: Mar 31, 2025\n",
    "updated: July 31, 2025\n",
    "\n",
    "## Data collection\n",
    "- [ ] create sample collection from Crossref from part 1\n",
    "- [ ] create shared corpus with works also found in OpenAlex matched on DOI\n",
    "    - take DOI from Crossref sample df_collated2 export\n",
    "    - send API call to OpenAlex for single work to select relevant elements or all and then refine down to elements needed for analysis\n",
    "        - example API: https://api.openalex.org/works?filter=doi:10.7717/peerj.4375&select=doi,title,id,publication_year,language,abstract_inverted_index\n",
    "    - reconstruct abstract from inverted \n",
    "        - [x] reconstruction code\n",
    "- [ ] Crossref schema and OpenAlex schema comparison\n",
    "    - Crossref schema: https://data.crossref.org/reports/help/schema_doc/5.3.1/index.html\n",
    "    - OpenAlex schema: https://docs.openalex.org/api-entities/works/work-object\n",
    "    - create diagram of this map\n",
    "    - create dictionary to build later\n",
    "- [ ] create mapping of metadata element from Crossref and its respective element in OpenAlex\n",
    "    - cr_title -> openalex_title\n",
    "    - cr_citedby_count -> openalex_citedby\n",
    "    - etc\n",
    "    - [ ] visualize/diagram\n",
    "- [ ] quantify differences\n",
    "    - [ ] exact match for numerical or absolute str values\n",
    "        - cited_by\n",
    "        - language\n",
    "        - URL\n",
    "        - doc_type\n",
    "        - license \n",
    "    - [ ] clean Crossref data for jats tags - what about MathML? Use regex pattern from Part 1<br>\n",
    "        #clean abstract<br>\n",
    "        title_abstract_df['abstract'] = title_abstract_df['abstract'].apply(lambda x: x.replace('\\n','').lstrip())<br>\n",
    "        #the following is from: https://github.com/ourresearch/openalex-walden/blob/main/notebooks/ingest/PDF.py<br>\n",
    "        title_abstract_df['abstract'] = title_abstract_df['abstract'].apply(lambda x: re.sub(r'<[^>]+>', '',x))<br>\n",
    "    - [ ] Levenshtein ratio for str values that can accept some variation without changing meaning: https://rapidfuzz.github.io/Levenshtein/\n",
    "        - title (may want to use Levenshtein.seqratio())\n",
    "        - abstract (may want to use Levenshtein.seqratio())\n",
    "- [ ] identify changes from publisher deposited data (Crossref) to OpenAlex\n",
    "    - DOI, title, abstract, license type, license, cited-by, language, and document type.\n",
    "- [ ] identify which error types occur: incorrect values, missing info, inconsistent values\n",
    "- [ ] visualize: other pubs have used Sankey diagram to show change - other ways to do this? Or improve upon the Sankey approach?\n",
    "\n",
    "## helpers:\n",
    "### Python\n",
    "- the Pyalex library: https://pypi.org/project/pyalex/#get-abstract\n",
    "- how to uninvert: https://stackoverflow.com/questions/72093757/running-python-loop-to-iterate-and-undo-inverted-index\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import pickle\n",
    "import json\n",
    "from colorama import Fore,Back,Style\n",
    "import time\n",
    "import csv\n",
    "import xmltodict #probably not needed here\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 10100 entries, ('journal-article', np.int64(0)) to ('book-chapter', np.int64(299))\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   DOI              10100 non-null  object\n",
      " 1   type             10100 non-null  object\n",
      " 2   title            10100 non-null  object\n",
      " 3   abstract         10100 non-null  object\n",
      " 4   language         4966 non-null   object\n",
      " 5   cited_by         10100 non-null  int64 \n",
      " 6   url              10100 non-null  object\n",
      " 7   license_version  5909 non-null   object\n",
      " 8   license_type     5909 non-null   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 814.8+ KB\n",
      "10100\n"
     ]
    }
   ],
   "source": [
    "# get samples from part 1\n",
    "#file = \"data/part_1_sample.txt\"\n",
    "#df = pd.read_csv(file, sep='\\t', encoding='utf-8', header=0)\n",
    "#print(df.columns) # look at column names\n",
    "##df.drop(['Unnamed: 0','level_0'], axis=1, inplace=True)\n",
    "#df.head(1) # just look at first one\n",
    "\n",
    "# load pickled data \n",
    "\n",
    "with open('data/part_1_sample_collected.pkl', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not have to specify it.\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame(data)\n",
    "# unpack 'license' into 'license_version' and 'license_type'\n",
    "df[['license_version', 'license_type']] = df['license'].apply(lambda x:pd.Series(x))\n",
    "# handle empty values\n",
    "\n",
    "# remove 'object' and 'license'\n",
    "df.drop(columns=['object','license'], inplace=True)\n",
    "\n",
    "# handle missing values\n",
    "df.isnull().sum()\n",
    "df.dtypes\n",
    "df.replace({None:np.nan,'None':np.nan}, inplace=True)\n",
    "df.info()\n",
    "print(len(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct abtract - from https://stackoverflow.com/questions/72093757/running-python-loop-to-iterate-and-undo-inverted-index\n",
    "\n",
    "\n",
    "def reconstruct_abstract(abstract:dict)-> str:\n",
    "\n",
    "    \"\"\"\n",
    "    This takes a dictionary of the inverted abstract\n",
    "    and returns a string of the reconstructed abstract.\n",
    "\n",
    "    Args:\n",
    "    abstract should be in the form of a dictionary. \n",
    "    Example:\n",
    "    abstract_inverted_index = {\n",
    "    'Despite':[0],\n",
    "    'growing':[1],\n",
    "   'interest': [2],\n",
    "    'in': [3],\n",
    "    'Open': [4],\n",
    "    'Access': [5],\n",
    "    '...': [6]\n",
    "\n",
    "    Returns:\n",
    "    String \n",
    "    \"\"\"\n",
    "\n",
    "    # Create a list of (word, index) pairs\n",
    "    word_index = []\n",
    "    for k, v in abstract.items():\n",
    "        for index in v:\n",
    "            word_index.append([k, index])\n",
    "\n",
    "    #print(word_index) # uncomment to see the sublists\n",
    "    # Sort the list based on index\n",
    "    word_index = sorted(word_index, key=lambda x: x[1]) # this sorts based on the second item in the sublist\n",
    "\n",
    "    # Join the words with a space\n",
    "    abstract = ' '.join([word for word, index in word_index])\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect OpenAlex data\n",
    "from functools import lru_cache\n",
    "\n",
    "# send call to OpenAelx API\n",
    "@lru_cache\n",
    "def get_openalex_data(doi:str)->dict:\n",
    "    \"\"\"\n",
    "    Arg: takes a DOI as a string without the resolver.\n",
    "    Return: A dictionary of values.\n",
    "\n",
    "    Note: oa_abstract is reconstructed from the function reconstruct_abstract()\n",
    "    \"\"\"\n",
    "    URL = f\"https://api.openalex.org/works?filter=doi:{doi}&select=doi,title,id,type,type_crossref,language,abstract_inverted_index,cited_by_count,is_paratext,primary_location\"\n",
    "    result = requests.get(URL)\n",
    "    \n",
    "    if result.status_code == 200:\n",
    "        data = result.json()\n",
    "\n",
    "        #parse json data into each element:\n",
    "        oa_doi = data['results'][0]['doi'].lstrip('https://doi.org/')\n",
    "        oa_title = data['results'][0]['title']\n",
    "        oa_id = data['results'][0]['id']\n",
    "        oa_type = data['results'][0]['type']\n",
    "        oa_type_crossref = data['results'][0]['type_crossref']\n",
    "        oa_language = data['results'][0]['language']\n",
    "        oa_abstract_inverted_index = data['results'][0]['abstract_inverted_index']\n",
    "        oa_cited_by_count = data['results'][0]['cited_by_count']\n",
    "        oa_is_paratext = data['results'][0]['is_paratext']\n",
    "        oa_primary_location_pdf_url = data['results'][0]['primary_location']['pdf_url']\n",
    "        oa_license = data['results'][0]['primary_location']['license']\n",
    "        oa_version = data['results'][0]['primary_location']['version']\n",
    "\n",
    "    # reconstruct abstract\n",
    "    oa_abstract = reconstruct_abstract(oa_abstract_inverted_index)\n",
    "\n",
    "    return {'oa_doi': oa_doi,\n",
    "            'oa_type':oa_type,\n",
    "            'oa_type_crossref':oa_type_crossref,\n",
    "            'oa_is_paratext':oa_is_paratext,\n",
    "            'oa_title':oa_title,\n",
    "            'oa_abstract':oa_abstract,\n",
    "            'oa_language':oa_language,\n",
    "            #'oa_abstract_inverted_index':oa_abstract_inverted_index,\n",
    "            'oa_cited_by_count':oa_cited_by_count,\n",
    "            'oa_primary_location_pdf_url':oa_primary_location_pdf_url,\n",
    "            'oa_license':oa_license,\n",
    "            'oa_version':oa_version,\n",
    "            'oa_id':oa_id,\n",
    "            }\n",
    "    # sleep so that you are below the 10 per second limit or 100k per day.\n",
    "    time.sleep(0.11)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oa_doi': '10.3390/su152215683',\n",
       " 'oa_type': 'article',\n",
       " 'oa_type_crossref': 'journal-article',\n",
       " 'oa_is_paratext': False,\n",
       " 'oa_title': 'Underpinning Quality Assurance: Identifying Core Testing Strategies for Multiple Layers of Internet-of-Things-Based Applications',\n",
       " 'oa_abstract': 'The Internet of Things (IoT) constitutes a digitally integrated network of intelligent devices equipped with sensors, software, and communication capabilities, facilitating data exchange among a multitude of digital systems via the Internet. Despite its pivotal role in the software development life-cycle (SDLC) for ensuring software quality in terms of both functional and non-functional aspects, testing within this intricate software–hardware ecosystem has been somewhat overlooked. To address this, various testing techniques are applied for real-time minimization of failure rates in IoT applications. However, the execution of a comprehensive test suite for specific IoT software remains a complex undertaking. This paper proposes a holistic framework aimed at aiding quality assurance engineers in delineating essential testing methods across different testing levels within the IoT. This delineation is crucial for effective quality assurance, ultimately reducing failure rates in real-time scenarios. Furthermore, the paper offers a mapping of these identified tests to each layer within the layered framework of the IoT. This comprehensive approach seeks to enhance the reliability and performance of IoT-based applications.',\n",
       " 'oa_language': 'en',\n",
       " 'oa_cited_by_count': 0,\n",
       " 'oa_primary_location_pdf_url': 'https://www.mdpi.com/2071-1050/15/22/15683/pdf?version=1699345258',\n",
       " 'oa_license': None,\n",
       " 'oa_version': 'publishedVersion',\n",
       " 'oa_id': 'https://openalex.org/W4388446692'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on single doi\n",
    "# 10.3390/su152215683\n",
    "get_openalex_data(\"10.3390/su152215683\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[35m██████████\u001b[0m| 20/20 [00:04<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['\u001b[35moa_doi', '\u001b[35moa_type', '\u001b[35moa_type_crossref',\n",
      "       '\u001b[35moa_is_paratext', '\u001b[35moa_title', '\u001b[35moa_abstract',\n",
      "       '\u001b[35moa_language', '\u001b[35moa_cited_by_count',\n",
      "       '\u001b[35moa_primary_location_pdf_url', '\u001b[35moa_license',\n",
      "       '\u001b[35moa_version', '\u001b[35moa_id'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oa_doi</th>\n",
       "      <th>oa_type</th>\n",
       "      <th>oa_type_crossref</th>\n",
       "      <th>oa_is_paratext</th>\n",
       "      <th>oa_title</th>\n",
       "      <th>oa_abstract</th>\n",
       "      <th>oa_language</th>\n",
       "      <th>oa_cited_by_count</th>\n",
       "      <th>oa_primary_location_pdf_url</th>\n",
       "      <th>oa_license</th>\n",
       "      <th>oa_version</th>\n",
       "      <th>oa_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1521/soco.2021.39.5.543</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>False</td>\n",
       "      <td>The Limits of Defaults: The Influence of Decis...</td>\n",
       "      <td>The stability of default effects to contextual...</td>\n",
       "      <td>en</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://openalex.org/W4206395497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1097/md.0000000000041851</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>False</td>\n",
       "      <td>Comparative analysis of demographic, clinical,...</td>\n",
       "      <td>The COVID-19 pandemic has brought a significan...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>cc-by-nc</td>\n",
       "      <td>publishedVersion</td>\n",
       "      <td>https://openalex.org/W4408845899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        oa_doi  ...                             oa_id\n",
       "0   10.1521/soco.2021.39.5.543  ...  https://openalex.org/W4206395497\n",
       "1  10.1097/md.0000000000041851  ...  https://openalex.org/W4408845899\n",
       "\n",
       "[2 rows x 12 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WARNING: This will take nearly 2 hours to run the full 10,100!\n",
    "from tqdm import tqdm\n",
    "\n",
    "openalex_data = []\n",
    "\n",
    "#REMOVE FOR FULL RUN!\n",
    "df = df.head(20)\n",
    "\n",
    "for doi in tqdm(df['DOI'],colour=\"MAGENTA\"):\n",
    "    result = get_openalex_data(doi)\n",
    "    openalex_data.append(result)\n",
    "\n",
    "df_openalex = pd.DataFrame(openalex_data)\n",
    "\n",
    "print(Fore.MAGENTA + df_openalex.columns)\n",
    "\n",
    "\n",
    "# save out the goods\n",
    "folder_to_be_saved = 'Part_2_data'\n",
    "if not os.path.exists(folder_to_be_saved):\n",
    "    os.makedirs(folder_to_be_saved)\n",
    "#export as .csv but tab separated\n",
    "file_to_be_saved = os.path.join(folder_to_be_saved, \"part_2_OA_sample_collected.csv\")\n",
    "\n",
    "df_openalex.to_csv(file_to_be_saved, sep='\\t', encoding='utf-8',na_rep='NA')\n",
    "\n",
    "# also save out as pickle to preserve data types\n",
    "pkl_to_be_saved = os.path.join(folder_to_be_saved, \"part_2_OA_sample_collected.pkl\")\n",
    "df_openalex.to_pickle(pkl_to_be_saved)\n",
    "\n",
    "df_openalex.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mpercent matched from Crossref: 100.0%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>match_on_doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1002/jocb.1534</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1039/d1re00315a</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1097/md.0000000000041851</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1186/s13052-024-01782-y</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.12957/cdf.2025.89476</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.1521/soco.2021.39.5.543</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.15407/internalmed2020.02b.029</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.16899/jcm.1241809</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.22214/ijraset.2023.49870</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.25136/2409-7136.2021.4.35160</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.31004/cendekia.v8i2.3226</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.32639/jimmba.v5i2.424</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.32996/jmcie.2021.2.2.10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.33871/21750769.2023.16.1.7435</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.3390/buildings12060818</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.3390/jmse12040650</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.51845/36.4.15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.54097/hset.v28i.4050</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.55529/jpdmhd.46.33.45</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.62810/jss.v6i3.106</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DOI  match_on_doi\n",
       "0                  10.1002/jocb.1534          True\n",
       "1                 10.1039/d1re00315a          True\n",
       "2        10.1097/md.0000000000041851          True\n",
       "3         10.1186/s13052-024-01782-y          True\n",
       "4            10.12957/cdf.2025.89476          True\n",
       "5         10.1521/soco.2021.39.5.543          True\n",
       "6   10.15407/internalmed2020.02b.029          True\n",
       "7               10.16899/jcm.1241809          True\n",
       "8        10.22214/ijraset.2023.49870          True\n",
       "9    10.25136/2409-7136.2021.4.35160          True\n",
       "10       10.31004/cendekia.v8i2.3226          True\n",
       "11          10.32639/jimmba.v5i2.424          True\n",
       "12        10.32996/jmcie.2021.2.2.10          True\n",
       "13  10.33871/21750769.2023.16.1.7435          True\n",
       "14         10.3390/buildings12060818          True\n",
       "15              10.3390/jmse12040650          True\n",
       "16                  10.51845/36.4.15          True\n",
       "17           10.54097/hset.v28i.4050          True\n",
       "18          10.55529/jpdmhd.46.33.45          True\n",
       "19             10.62810/jss.v6i3.106          True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare Crossref df and oa df match on DOI\n",
    "# new df with a boolean value if they share: doi, match_on_doi,...\n",
    "# this will expand out for other boolean values\n",
    "\n",
    "# match on df['doi'] and df_openalex['oa_doi']\n",
    "match_on_doi_df = df[['DOI']].merge(df_openalex[['oa_doi']], left_on='DOI', right_on='oa_doi', how='outer')\n",
    "\n",
    "match_on_doi_df['match_on_doi'] = match_on_doi_df['DOI'] == match_on_doi_df['oa_doi']\n",
    "\n",
    "match_on_doi_df = match_on_doi_df.drop(['oa_doi'], axis=1)\n",
    "\n",
    "print(Fore.CYAN + f\"percent matched from Crossref: {len(match_on_doi_df)/len(df)*100:.1f}%\")\n",
    "\n",
    "match_on_doi_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] quantify differences\n",
    "    - [ ] exact match for numerical or absolute str values\n",
    "        - cited_by\n",
    "        - language\n",
    "        - URL\n",
    "        - doc_type\n",
    "        - license \n",
    "    - [ ] Levenshtein ratio for str values that can accept some variation without changing meaning: https://rapidfuzz.github.io/Levenshtein/\n",
    "        - title (may want to use Levenshtein.seqratio())\n",
    "        - abstract (may want to use Levenshtein.seqratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make you a copy that does not have effects on the original\n",
    "crossref_df = df.copy(deep=True)\n",
    "\n",
    "#load you in the openalex data from the pickle\n",
    "with open('Part_2_data/part_2_OA_sample_collected.pkl', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not have to specify it.\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# create dataframe\n",
    "openalex_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mCrossref columns: \n",
      "Index(['DOI', 'type', 'title', 'abstract', 'language', 'cited_by', 'url',\n",
      "       'license_version', 'license_type'],\n",
      "      dtype='object')\n",
      "\u001b[95m\n",
      "------\n",
      "OpenAlex columns: \n",
      "Index(['oa_doi', 'oa_type', 'oa_type_crossref', 'oa_is_paratext', 'oa_title',\n",
      "       'oa_abstract', 'oa_language', 'oa_cited_by_count',\n",
      "       'oa_primary_location_pdf_url', 'oa_license', 'oa_version', 'oa_id'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oa_doi</th>\n",
       "      <th>oa_type</th>\n",
       "      <th>oa_type_crossref</th>\n",
       "      <th>oa_is_paratext</th>\n",
       "      <th>oa_title</th>\n",
       "      <th>oa_abstract</th>\n",
       "      <th>oa_language</th>\n",
       "      <th>oa_cited_by_count</th>\n",
       "      <th>oa_primary_location_pdf_url</th>\n",
       "      <th>oa_license</th>\n",
       "      <th>oa_version</th>\n",
       "      <th>oa_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1521/soco.2021.39.5.543</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>False</td>\n",
       "      <td>The Limits of Defaults: The Influence of Decis...</td>\n",
       "      <td>The stability of default effects to contextual...</td>\n",
       "      <td>en</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://openalex.org/W4206395497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1097/md.0000000000041851</td>\n",
       "      <td>article</td>\n",
       "      <td>journal-article</td>\n",
       "      <td>False</td>\n",
       "      <td>Comparative analysis of demographic, clinical,...</td>\n",
       "      <td>The COVID-19 pandemic has brought a significan...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>cc-by-nc</td>\n",
       "      <td>publishedVersion</td>\n",
       "      <td>https://openalex.org/W4408845899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        oa_doi  ...                             oa_id\n",
       "0   10.1521/soco.2021.39.5.543  ...  https://openalex.org/W4206395497\n",
       "1  10.1097/md.0000000000041851  ...  https://openalex.org/W4408845899\n",
       "\n",
       "[2 rows x 12 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Fore.LIGHTCYAN_EX + f\"Crossref columns: \\n{crossref_df.columns}\")\n",
    "print(Fore.LIGHTMAGENTA_EX + f\"\\n------\\nOpenAlex columns: \\n{openalex_df.columns}\")\n",
    "crossref_df.head(2)\n",
    "openalex_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overall changes\n",
    "- [ ] identify changes from publisher deposited data (Crossref) to OpenAlex\n",
    "    - DOI, title, abstract, license type, license, cited-by, language, and document type -> 0 for missing, 1 for present\n",
    "    - create table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOI specific metadata\n",
    "- [ ] Change in DOI URL from Crossref to OpenAlex, (0,1)\n",
    "- [ ] count of those that have https vs http (as an indicator of link rot)\n",
    "- [ ] count of HTTP status code on all URLs\n",
    "- [ ] count of those not working (such as 400)\n",
    "- [ ] create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### publication type\n",
    "- [ ] count of each type\n",
    "- [ ] change from Crossref to Openalex, 0,1?\n",
    "- [ ] % distribution \n",
    "- [ ] maybe a good place for a sankey diagram showing changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### title\n",
    "- [ ] change between Crossref and OpenAlex 0,1?\n",
    "- [ ] count of tokens in each\n",
    "- [ ] count of stopwords\n",
    "- [ ] count of punctuation\n",
    "- [ ] count of special char, formating char\n",
    "- [ ] count of numerals\n",
    "- [ ] count of tags or other non-text elements\n",
    "- [ ] visualize distribution of these across both databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### abstract\n",
    "- [ ] change between Crossref and OpenAlex?\n",
    "- [ ] count of tokens in each\n",
    "- [ ] count of stopwords\n",
    "- [ ] count of punctuation\n",
    "- [ ] count of special char, formating char\n",
    "- [ ] count of numerals\n",
    "- [ ] count of tags or other non-text elements\n",
    "- [ ] visualize distribution of these across both databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cited by count\n",
    "- [ ] std dev of differences between two samples\n",
    "- [ ] n with change\n",
    "- [ ] % affected\n",
    "- [ ] visualize to see if one database favors more than the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### license\n",
    "- [ ] change between Crossref and OpenAlex?\n",
    "- [ ] count of types for each\n",
    "- [ ] count of those with licenses vs without\n",
    "- [ ] % of those with \n",
    "- [ ] count of common or proprietary licenses\n",
    "- [ ] visualization of distribution of license types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### languages\n",
    "- [ ] change between Crossref and OpenAlex\n",
    "- [ ] count of types\n",
    "- [ ] % declared in abstract\n",
    "    - found in XML API\n",
    "- [ ] % declared in journal title level\n",
    "    - found in REST API\n",
    "- [ ] visualization of distribution of language types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative Analysis\n",
    "\n",
    "### License\n",
    "IF there are differences, an examination of changes between two sources. This may require a subset based on filtering from above. \n",
    "- [ ] comparison of license in each source\n",
    "- [ ] apply an error classification: incorrect, missing, inconsistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### title and abstract\n",
    "- [ ] filter df from above for those with differences \n",
    "    - [ ] use subset if needed due to quantity\n",
    "- [ ] compare title from each source based on Levenshtein seqratio\n",
    "- [ ] compare abstract from each source based on Levenshtein seqratio\n",
    "- [ ] apply classification\n",
    "- [ ] identify error types \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diagram of crosswalk between Crossref and OpenAlex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Crossref schema and OpenAlex schema comparison\n",
    "    - Crossref schema: https://data.crossref.org/reports/help/schema_doc/5.3.1/index.html\n",
    "    - OpenAlex schema: https://docs.openalex.org/api-entities/works/work-object\n",
    "    - create diagram of this map\n",
    "    - create dictionary to build later\n",
    "    - [ ] create mapping of metadata element from Crossref and its respective element in OpenAlex\n",
    "    - cr_title -> openalex_title\n",
    "    - cr_citedby_count -> openalex_citedby\n",
    "    - etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#parse json data into each element:\u001b[39;00m\n",
      "\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;66;03m#returned from OpenAlex REST API\u001b[39;00m\n",
      "\u001b[0;32m----> 3\u001b[0m oa_doi \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoi\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://doi.org/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m      4\u001b[0m oa_title \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;32m      5\u001b[0m oa_id \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m: 'results'"
     ]
    }
   ],
   "source": [
    "#parse json data into each element:\n",
    "data = data #returned from OpenAlex REST API\n",
    "oa_doi = data['results'][0]['doi'].lstrip('https://doi.org/')\n",
    "oa_title = data['results'][0]['title']\n",
    "oa_id = data['results'][0]['id']\n",
    "oa_type = data['results'][0]['type']\n",
    "oa_type_crossref = data['results'][0]['type_crossref']\n",
    "oa_language = data['results'][0]['language']\n",
    "oa_abstract_inverted_index = data['results'][0]['abstract_inverted_index']\n",
    "oa_cited_by_count = data['results'][0]['cited_by_count']\n",
    "oa_is_paratext = data['results'][0]['is_paratext']\n",
    "oa_primary_location_pdf_url = data['results'][0]['primary_location']['pdf_url']\n",
    "oa_license = data['results'][0]['primary_location']['license']\n",
    "oa_version = data['results'][0]['primary_location']['version']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

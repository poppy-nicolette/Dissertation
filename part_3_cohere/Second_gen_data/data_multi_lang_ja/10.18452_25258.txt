DOI: 10.18452/25258
Title: そこにいる人はいますか?: 人間と AI の情報相互作用における感情と信頼のモデルに向けて Is anybody in there?: Towards a model of affect and trust in human – AI information interactions
Abstract: 機械学習を利用した検索エンジンの進歩により、ユーザーがこれらのシステムを信頼に値するものと認識する可能性が高まります。機械学習を利用するアルゴリズム システムのコンテキストにおける信頼の性質と意味が調査され、その結果得られる信頼の概念がモデル化されます。現在の人工知能は、信頼できるとみなされるために必要な道徳的自律性の要件を満たしていませんが、人々は依然として道徳的自律性の認識に基づいて誤った信頼を抱く可能性があります。アルゴリズム システムを信頼するユーザーは、情報のやり取りに対する重要な関与や評価を制限します。 Ingwersen と Jarvelin のインタラクティブな情報探索と検索のための統合モデルを適用した、情報相互作用における信頼の役割の予備的な高レベル モデルが、例として Google 検索エンジンを使用して提案されています。私たちは、信頼態度の形成につながる可能性のある社会的な方法でユーザーが情報システムに反応する可能性があることを認識する必要があります。情報専門家として、私たちはユーザーが自律的であると認識している場合でも、情報システムとの対話に批判的に関与し続けることを奨励する介入を開発したいと考えています。 dvancements in search engines that utilize machine learning increase the likelihood that users will perceive these systems as worthy of trust. The nature and implications of trust in the context of algorithmic systems that utilize machine learning is examined and the resulting conception of trust is modelled. While current artificial intelligence does not meet the requirements of moral autonomy necessary to be considered trustworthy, people may still engage in misplaced trust based on the perception of moral autonomy. Users who place their trust in algorithmic systems limit their critical engagement with, and assessment of, the information interaction. A preliminary high-level model of trust’s role in information interactions adapting Ingwersen and Jarvelin’s Integrative Model for Interactive Information Seeking and Retrieval is proposed using the Google search engine as an example. We need to recognize that is it possible for users to react to information systems in a social manner that may lead to the formation of trust attitudes. As information professionals we want to develop interventions that will encourage users to stay critically engaged with their interactions with information systems, even when they perceive them to be autonomous.
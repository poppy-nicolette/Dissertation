DOI: 10.1145/3543873.3587655
Title: プロンプト構文の解読: 大規模言語モデルにおける知識検索への影響の分析 Decoding Prompt Syntax: Analysing its Impact on Knowledge Retrieval in Large Language Models
Abstract: 大規模言語モデル (LLM) には、高度なアーキテクチャと大規模な言語データセットでのトレーニングを備えており、未踏の知識が含まれています。この知識を推測する 1 つの方法は、cloze スタイルのプロンプトを使用することです。通常、これらのプロンプトは、LLM が必要な情報をエンコードしている場合でも、プロンプトの表現がナレッジ検索のパフォーマンスに影響を与えるため、手動で設計されます。この論文では、LLM の知識検索能力に対するプロンプト構文の影響を研究します。テンプレートベースのアプローチを使用して、単純なプロンプトをより複雑な文法構造を持つプロンプトに言い換えます。次に、これらの構造的には異なりますが、意味的には同等のプロンプトの LLM パフォーマンスを分析します。私たちの研究では、複雑な形式の文よりも単純なプロンプトの方が効果があることが明らかになりました。単純なリレーション (1:1) の構文上のバリエーション全体でのパフォーマンスは依然として最高ですが、異なる類型ではわずかに低下します。これらの結果は、LLM での知識検索には単純なプロンプト構造の方が効果的であることを裏付けており、プロンプト構文がさまざまなタスクに与える影響についての今後の研究の動機となります。 Large Language Models (LLMs), with their advanced architectures and training on massive language datasets, contain unexplored knowledge. One method to infer this knowledge is through the use of cloze-style prompts. Typically, these prompts are manually designed because the phrasing of these prompts impacts the knowledge retrieval performance, even if the LLM encodes the desired information. In this paper, we study the impact of prompt syntax on the knowledge retrieval capacity of LLMs. We use a template-based approach to paraphrase simple prompts into prompts with a more complex grammatical structure. We then analyse the LLM performance for these structurally different but semantically equivalent prompts. Our study reveals that simple prompts work better than complex forms of sentences. The performance across the syntactical variations for simple relations (1:1) remains best, with a marginal decrease across different typologies. These results reinforce that simple prompt structures are more effective for knowledge retrieval in LLMs and motivate future research into the impact of prompt syntax on various tasks.
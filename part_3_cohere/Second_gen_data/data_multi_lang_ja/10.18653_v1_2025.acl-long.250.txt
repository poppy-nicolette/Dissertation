DOI: 10.18653/v1/2025.acl-long.250
Title: パンドラの箱またはアラジンのランプ: 大規模言語モデルにおける RAG ノイズの役割を明らかにする包括的な分析 Pandora’s Box or Aladdin’s Lamp: A Comprehensive Analysis Revealing the Role of RAG Noise in Large Language Models
Abstract: 検索拡張生成 (RAG) は、大規模言語モデル (LLM) における幻覚に対処するための重要な方法として登場しました。最近の研究では RAG モデルを複雑なノイズの多いシナリオに拡張しましたが、これらの調査は多くの場合、限られた種類のノイズに限定されており、ノイズは本質的に LLM にとって有害で​​あり、現実世界の検索環境から逸脱する可能性があり、実際の適用性が制限されます。この論文では、言語学的観点から 7 つの異なるノイズ タイプを定義し、複数のデータセットと推論タスクを含む包括的な評価フレームワークである Noise RAG ベンチマーク (NoiserBench) を確立します。さまざまなアーキテクチャと規模を持つ 8 つの代表的な LLM の経験的評価を通じて、これらのノイズが、LLM にとって有益なノイズ (別名有益なノイズ) と LLM にとって有害なノイズ (別名、有害なノイズ) の 2 つの実用的なグループにさらに分類できることを明らかにしました。一般に有害なノイズはパフォーマンスを低下させますが、有益なノイズはモデルの機能と全体的なパフォーマンスのいくつかの側面を向上させる可能性があります。私たちの分析は、堅牢な RAG ソリューションを開発し、さまざまな検索シナリオ全体で幻覚を軽減するための洞察を提供します。 Retrieval-Augmented Generation (RAG) has emerged as a crucial method for addressing hallucinations in large language models (LLMs). While recent research has extended RAG models to complex noisy scenarios, these explorations often confine themselves to limited noise types and presuppose that noise is inherently detrimental to LLMs, potentially deviating from real-world retrieval environments and restricting practical applicability. In this paper, we define seven distinct noise types from a linguistic perspective and establish a Noise RAG Benchmark (NoiserBench), a comprehensive evaluation framework encompassing multiple datasets and reasoning tasks. Through empirical evaluation of eight representative LLMs with diverse architectures and scales, we reveal that these noises can be further categorized into two practical groups: noise that is beneficial to LLMs (aka beneficial noise) and noise that is harmful to LLMs (aka harmful noise). While harmful noise generally impairs performance, beneficial noise may enhance several aspects of model capabilities and overall performance. Our analysis offers insights for developing robust RAG solutions and mitigating hallucinations across diverse retrieval scenarios. 
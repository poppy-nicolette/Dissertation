DOI: 10.48550/arXiv.2307.03172
Title: 途中で迷った: 言語モデルが長いコンテキストをどのように使用するか Lost in the Middle: How Language Models Use Long Contexts
Abstract: 最近の言語モデルには長いコンテキストを入力として受け取る機能がありますが、長いコンテキストをどのように適切に使用するかについてはほとんど知られていません。入力コンテキストで関連情報を識別する必要がある 2 つのタスク、つまり複数ドキュメントの質問応答とキーと値の取得に関する言語モデルのパフォーマンスを分析します。関連する情報の位置を変更すると、パフォーマンスが大幅に低下する可能性があることがわかりました。これは、現在の言語モデルが長い入力コンテキストの情報を確実に利用していないことを示しています。特に、関連情報が入力コンテキストの最初または最後に発生する場合にパフォーマンスが最も高くなることがよくありますが、モデルが長いコンテキストの途中で関連情報にアクセスする必要がある場合には、明示的に長いコンテキスト モデルであっても、パフォーマンスが大幅に低下することが観察されています。私たちの分析により、言語モデルが入力コンテキストをどのように使用するかについての理解を深めることができ、将来のロングコンテキスト言語モデルに新しい評価プロトコルが提供されます。 While recent language models have the ability to take long contexts as input, relatively little is known about how well they use longer context. We analyze the performance of language models on two tasks that require identifying relevant information in their input contexts: multi-document question answering and key-value retrieval. We find that performance can degrade significantly when changing the position of relevant information, indicating that current language models do not robustly make use of information in long input contexts. In particular, we observe that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context language models.
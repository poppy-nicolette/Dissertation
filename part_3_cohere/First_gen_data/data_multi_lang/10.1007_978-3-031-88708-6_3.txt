DOI: 10.1007/978-3-031-88708-6_3
Title: 関連性はレトリバーからジェネレーターにぼろきれに伝播されますか？ Is Relevance Propagated from Retriever to Generator in RAG?
Abstract: 検索拡張生成（RAG）は、通常、コレクションから取得された一連のドキュメントの形で、プロンプトの大規模な言語モデル（LLM）への一連のドキュメントの形で、質問の回答などの下流タスクのパフォーマンスを潜在的に改善するためのフレームワークです。一連のトップランクのドキュメントの関連性を最大化するという標準検索タスクの目的とは異なり、RAGシステムの目的は、ドキュメントのユーティリティがLLMプロンプトの追加コンテキスト情報の一部としてそれを含めることがダウンストリームタスクを改善するかどうかを示します。既存の研究では、知識集約型の言語タスク（KILT）のRAGコンテキストの関連性の役割を調査します。対照的に、私たちの仕事では、関連性は、情報を求めるタスクのクエリとドキュメントの間の局所的な重複の関連性に対応しています。具体的には、IRテストコレクションを利用して、局所的に関連するドキュメントで構成されるRAGコンテキストが下流のパフォーマンスの改善につながるかどうかを経験的に調査します。私たちの実験は、次の発見につながります。（a）関連性と有用性の間には小さな正の相関があります。 （b）この相関は、コンテキストサイズの増加とともに減少します（k-shotのkの値が高い）。 （c）より効果的な検索モデルは、一般に、下流のラグパフォーマンスの向上につながります。 Retrieval Augmented Generation (RAG) is a framework for incorporating external knowledge, usually in the form of a set of documents retrieved from a collection, as a part of a prompt to a large language model (LLM) to potentially improve the performance of a downstream task, such as question answering. Different from a standard retrieval task’s objective of maximising the relevance of a set of top-ranked documents, a RAG system’s objective is rather to maximise their total utility, where the utility of a document indicates whether including it as a part of the additional contextual information in an LLM prompt improves a downstream task. Existing studies investigate the role of the relevance of a RAG context for knowledge-intensive language tasks (KILT), where relevance essentially takes the form of answer containment. In contrast, in our work, relevance corresponds to that of topical overlap between a query and a document for an information seeking task. Specifically, we make use of an IR test collection to empirically investigate whether a RAG context comprised of topically relevant documents leads to improved downstream performance. Our experiments lead to the following findings: (a) there is a small positive correlation between relevance and utility; (b) this correlation decreases with increasing context sizes (higher values of k in k-shot); and (c) a more effective retrieval model generally leads to better downstream RAG performance.

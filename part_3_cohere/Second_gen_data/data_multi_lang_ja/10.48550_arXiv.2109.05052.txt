DOI: 10.48550/arXiv.2109.05052
Title: 質問応答におけるエンティティベースの知識の矛盾 Entity-Based Knowledge Conflicts in Question Answering
Abstract: 知識依存タスクでは、通常、トレーニング時に学習されるパラメトリックな知識と、推論時にパッセージとして与えられるコンテキスト的な知識の 2 つの情報源が使用されます。モデルがこれらのソースをどのように組み合わせて使用​​するかを理解するために、コンテキスト情報が学習された情報と矛盾する、知識の競合の問題を形式化します。人気モデルの行動を分析することで、記憶された情報（幻覚の原因）への過度の依存度を測定し、この行動を悪化させる重要な要因を明らかにします。最後に、パラメトリック知識への過度の依存を軽減する簡単な方法を提案します。これにより、幻覚が最小限に抑えられ、分布外一般化が 4% ～ 7% 改善されます。私たちの調査結果は、実践者が読書よりも幻覚を起こすモデルの傾向を評価することの重要性を示し、また、私たちの緩和戦略が進化する情報（つまり、時間依存のクエリ）への一般化を促進することを示しています。こうした実践を奨励するために、私たちは知識の衝突を生成するためのフレームワークをリリースしました。 Knowledge-dependent tasks typically use two sources of knowledge: parametric, learned at training time, and contextual, given as a passage at inference time. To understand how models use these sources together, we formalize the problem of knowledge conflicts, where the contextual information contradicts the learned information. Analyzing the behaviour of popular models, we measure their over-reliance on memorized information (the cause of hallucinations), and uncover important factors that exacerbate this behaviour. Lastly, we propose a simple method to mitigate over-reliance on parametric knowledge, which minimizes hallucination, and improves out-of-distribution generalization by 4%-7%. Our findings demonstrate the importance for practitioners to evaluate model tendency to hallucinate rather than read, and show that our mitigation strategy encourages generalization to evolving information (i.e., time-dependent queries). To encourage these practices, we have released our framework for generating knowledge conflicts.
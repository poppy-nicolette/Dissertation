DOI: 10.48550/arXiv.2109.05052
Title: エンティティベースの知識は、問題の回答で矛盾します Entity-Based Knowledge Conflicts in Question Answering
Abstract: 知識依存のタスクは通常、2つの知識源を使用します。パラメトリック、トレーニング時に学習し、文脈的な文脈を推論時に通過するものとして与えられます。モデルがこれらのソースをどのように使用するかを理解するために、知識の競合の問題を形式化します。ここでは、文脈情報が学習情報と矛盾します。人気モデルの動作を分析すると、記憶された情報（幻覚の原因）に対する過度の依存を測定し、この行動を悪化させる重要な要因を明らかにします。最後に、幻覚を最小限に抑え、分散型の一般化を4％〜7％改善するパラメトリック知識への過度の依存を緩和する簡単な方法を提案します。私たちの調査結果は、実践者が読み物ではなく幻覚のモデル傾向を評価することの重要性を示しており、緩和戦略が一般化が進化する情報（つまり、時間依存のクエリ）を促進することを示しています。これらのプラクティスを奨励するために、知識の対立を生み出すためのフレームワークをリリースしました。 Knowledge-dependent tasks typically use two sources of knowledge: parametric, learned at training time, and contextual, given as a passage at inference time. To understand how models use these sources together, we formalize the problem of knowledge conflicts, where the contextual information contradicts the learned information. Analyzing the behaviour of popular models, we measure their over-reliance on memorized information (the cause of hallucinations), and uncover important factors that exacerbate this behaviour. Lastly, we propose a simple method to mitigate over-reliance on parametric knowledge, which minimizes hallucination, and improves out-of-distribution generalization by 4%-7%. Our findings demonstrate the importance for practitioners to evaluate model tendency to hallucinate rather than read, and show that our mitigation strategy encourages generalization to evolving information (i.e., time-dependent queries). To encourage these practices, we have released our framework for generating knowledge conflicts.


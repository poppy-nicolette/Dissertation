DOI: 10.48550/arXiv.2402.01788
Title: LitLLM: 科学文献レビューのためのツールキット LitLLM: A Toolkit for Scientific Literature Review
Abstract: 科学論文の文献レビューを実施することは、研究とその限界を理解し、既存の研究に基づいて構築するために不可欠です。これは面倒な作業であるため、文献レビューの自動生成機能は魅力的です。残念ながら、大規模言語モデル (LLM) を使用してこのようなレビューを生成する既存の作品の多くには、重大な制限があります。彼らは幻覚を起こし、実際とは異なる情報を生成し、訓練されていない最新の研究を無視する傾向があります。これらの制限に対処するために、私たちは、検索拡張生成 (RAG) の原理、LLM の助けを借りた特殊なプロンプトおよび指示技術に基づいて動作するツールキットを提案します。私たちのシステムはまず Web 検索を開始し、既製の LLM を使用してユーザーが提供した要約をキーワードに要約して関連論文を検索します。著者は、関連する論文やキーワードを補足することで検索を強化し、カスタマイズされた検索プロセスに貢献できます。次に、システムは、ユーザーが提供した要約に基づいて、取得した論文を再ランク付けします。最後に、再ランキング結果と要約に基づいて関連作品セクションが生成されます。従来の方法と比較して文献レビューにかかる時間と労力が大幅に削減され、当社のツールキットは効率的な代替手段として確立されています。 Conducting literature reviews for scientific papers is essential for understanding research, its limitations, and building on existing work. It is a tedious task which makes an automatic literature review generator appealing. Unfortunately, many existing works that generate such reviews using Large Language Models (LLMs) have significant limitations. They tend to hallucinate-generate non-actual information-and ignore the latest research they have not been trained on. To address these limitations, we propose a toolkit that operates on Retrieval Augmented Generation (RAG) principles, specialized prompting and instructing techniques with the help of LLMs. Our system first initiates a web search to retrieve relevant papers by summarizing user-provided abstracts into keywords using an off-the-shelf LLM. Authors can enhance the search by supplementing it with relevant papers or keywords, contributing to a tailored retrieval process. Second, the system re-ranks the retrieved papers based on the user-provided abstract. Finally, the related work section is generated based on the re-ranked results and the abstract. There is a substantial reduction in time and effort for literature review compared to traditional methods, establishing our toolkit as an efficient alternative. 
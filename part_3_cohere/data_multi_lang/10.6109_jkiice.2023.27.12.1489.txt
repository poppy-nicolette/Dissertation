DOI: 10.6109/jkiice.2023.27.12.1489
Title: M-RAG：メタデータ検索の高等世代によるオープンドメインの質問応答を強化します M-RAG: Enhancing Open-domain Question Answering with Metadata Retrieval-Augmented Generation
Abstract: このホワイトペーパーでは、1つ以上のドキュメントのオープンドメイン質問応答（ODQA）システムで効果的な検索のために、メタデータ検索の高等発電（M-RAG）と呼ばれる方法を提案し、そのパフォーマンスを比較します。これを達成するために、メタデータを含む埋め込みを利用し、自動回答生成にGPT-3.5-Turbo-16KやGPT-4などの生成モデルを使用します。このアプローチを通じて、生成モデル（GPT-3.5、GPT-4）は、メタデータを介したクエリドキュメントの順序とコンテキストを理解することができます。さらに、迅速なエンジニアリングを通じてソース情報と元のテキスト要件を組み込むことにより、問題回答（QA）のソース属性機能をアクティブにし、それにより回答の精度を向上させます。この論文の結果として、LLMが持たない情報は外部ソースから取得でき、適切な応答を見つけることができます。実験結果は、この方法が同じ外部推論ODQAシステムと比較して最大46％のパフォーマンス改善を示し、既存のRAGメソッドよりも6％の改善を示したことを示しています。 This paper proposes a method called Metadata Retrieval-Augmented Generation (M-RAG) for effective search in open-domain Question Answering (ODQA) systems for one or more documents and compares its performance. To achieve this, it utilizes embeddings that include metadata and employs generative models such as gpt-3.5-turbo-16k and gpt-4 for automated answer generation. Through this approach, the generative models (gpt-3.5, gpt-4) are able to understand the order and context of query documents through metadata. Additionally, by incorporating source information and original text requirements through prompt engineering, it activates source attribution capabilities in question-answering (QA), thereby enhancing answer accuracy. As a result of this paper, information that LLM does not have can be retrieved from external sources and an appropriate response can be found.. Experimental results show that this method exhibited up to a 46% performance improvement compared to the same external inference ODQA system and a 6% improvement over the existing RAG method
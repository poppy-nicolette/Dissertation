DOI: 10.1145/3637528.3671470
Title: RAG ミーティング LLM に関する調査: 検索拡張された大規模言語モデルに向けて A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models
Abstract: AI の最も高度な技術の 1 つである検索拡張生成 (RAG) は、信頼性の高い最新の外部知識を提供し、多数のタスクに大きな利便性をもたらします。特に AI 生成コンテンツ (AIGC) の時代では、追加の知識を提供する強力な検索能力により、RAG は既存の生成 AI による高品質の出力の生成を支援できます。最近、大規模言語モデル (LLM) は、言語の理解と生成において革新的な能力を実証しましたが、依然として幻覚や古い内部知識などの固有の制限に直面しています。最新の有用な補助情報を提供する RAG の強力な機能を考慮して、検索拡張大規模言語モデル (RA-LLM) は、モデルの内部知識だけに依存するのではなく、外部の信頼できる知識ベースを利用して、LLM で生成されるコンテンツの品質を強化するために登場しました。この調査では、RA-LLM に関する既存の研究研究を包括的にレビューし、3 つの主要な技術的観点をカバーします。さらに、より深い洞察を提供するために、現在の限界と将来の研究のいくつかの有望な方向性について議論します。 one of the most advanced techniques in AI, Retrieval-Augmented Generation (RAG) can offer reliable and up-to-date external knowledge, providing huge convenience for numerous tasks. Particularly in the era of AI-Generated Content (AIGC), the powerful capacity of retrieval in providing additional knowledge enables RAG to assist existing generative AI in producing high-quality outputs. Recently, Large Language Models (LLMs) have demonstrated revolutionary abilities in language understanding and generation, while still facing inherent limitations such as hallucinations and out-of-date internal knowledge. Given the powerful abilities of RAG in providing the latest and helpful auxiliary information, Retrieval-Augmented Large Language Models (RA-LLMs) have emerged to harness external and authoritative knowledge bases, rather than solely relying on the model's internal knowledge, to augment the quality of the generated content of LLMs. In this survey, we comprehensively review existing research studies in RA-LLMs, covering three primary technical perspectives: Furthermore, to deliver deeper insights, we discuss current limitations and several promising directions for future research.
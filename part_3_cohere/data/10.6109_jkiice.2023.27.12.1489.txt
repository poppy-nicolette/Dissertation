DOI: 10.6109/jkiice.2023.27.12.1489
Abstract: This paper proposes a method called Metadata Retrieval-Augmented Generation (M-RAG) for effective search in open-domain Question Answering (ODQA) systems for one or more documents and compares its performance. To achieve this, it utilizes embeddings that include metadata and employs generative models such as gpt-3.5-turbo-16k and gpt-4 for automated answer generation. Through this approach, the generative models (gpt-3.5, gpt-4) are able to understand the order and context of query documents through metadata. Additionally, by incorporating source information and original text requirements through prompt engineering, it activates source attribution capabilities in question-answering (QA), thereby enhancing answer accuracy. As a result of this paper, information that LLM does not have can be retrieved from external sources and an appropriate response can be found.. Experimental results show that this method exhibited up to a 46% performance improvement compared to the same external inference ODQA system and a 6% improvement over the existing RAG method
DOI: 10.48550/arXiv.1909.06146
Title: PubMedQA: 生物医学研究の質問応答のためのデータセット PubMedQA: A Dataset for Biomedical Research Question Answering
Abstract: PubMed 抄録から収集された新しい生物医学質問応答 (QA) データセットである PubMedQA を紹介します。 PubMedQA の任務は、対応する抄録を使用して、研究上の質問に「はい」/「いいえ」/「多分」で答えることです (例: 術前スタチンは冠動脈バイパス移植後の心房細動を軽減しますか?)。 PubMedQA には、専門家による注釈付きの 1,000 件、ラベルのない 61,200 件、人工的に生成された 211,300 件の QA インスタンスがあります。各 PubMedQA インスタンスは、(1) 既存の研究論文のタイトルまたはそこから派生した質問、(2) 結論のない対応する要約であるコンテキスト、(3) 要約の結論であり、おそらく研究の質問に答える長い回答、および (4) 結論を要約する「はい/いいえ/たぶん」の回答で構成されます。 PubMedQA は、質問に答えるために生物医学研究テキスト、特に定量的な内容についての推論が必要とされる最初の QA データセットです。追加の監視として長文回答のバッグオブワード統計を使用した BioBERT のマルチフェーズ微調整である当社の最高パフォーマンス モデルは、人間による 1 人のパフォーマンスの精度 78.0% および多数派ベースラインの精度 55.2% と比較して、精度 68.1% を達成しており、改善の余地が多く残されています。 We introduce PubMedQA, a novel biomedical question answering (QA) dataset collected from PubMed abstracts. The task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative statins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts. PubMedQA has 1k expert-annotated, 61.2k unlabeled and 211.3k artificially generated QA instances. Each PubMedQA instance is composed of (1) a question which is either an existing research article title or derived from one, (2) a context which is the corresponding abstract without its conclusion, (3) a long answer, which is the conclusion of the abstract and, presumably, answers the research question, and (4) a yes/no/maybe answer which summarizes the conclusion. PubMedQA is the first QA dataset where reasoning over biomedical research texts, especially their quantitative contents, is required to answer the questions. Our best performing model, multi-phase fine-tuning of BioBERT with long answer bag-of-word statistics as additional supervision, achieves 68.1% accuracy, compared to single human performance of 78.0% accuracy and majority-baseline of 55.2% accuracy, leaving much room for improvement.
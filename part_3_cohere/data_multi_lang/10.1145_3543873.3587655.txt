DOI: 10.1145/3543873.3587655
Title: デコードプロンプト構文：大規模な言語モデルでの知識検索への影響の分析 Decoding Prompt Syntax: Analysing its Impact on Knowledge Retrieval in Large Language Models
Abstract: 大規模な言語モデル（LLMS）は、高度なアーキテクチャと大規模な言語データセットに関するトレーニングを備えており、未開拓の知識が含まれています。この知識を推測する1つの方法は、Clozeスタイルのプロンプトを使用することです。通常、これらのプロンプトは、これらのプロンプトのフレージングが、LLMが目的の情報をエンコードする場合でも、知識の検索パフォーマンスに影響を与えるため、手動で設計されています。この論文では、LLMSの知識検索能力に対する迅速な構文の影響を研究します。テンプレートベースのアプローチを使用して、より複雑な文法構造を持つ単純なプロンプトを言い換えます。次に、これらの構造的に異なるが意味的に同等のプロンプトのLLMパフォーマンスを分析します。私たちの研究は、単純なプロンプトが複雑な形式の文よりもうまく機能することを明らかにしています。単純な関係の構文的なバリエーション全体のパフォーマンス（1：1）は、異なる類型にわたってわずかな減少を伴う最高のままです。これらの結果は、単純な迅速な構造がLLMSの知識の検索に対してより効果的であり、さまざまなタスクに対する迅速な構文の影響に関する将来の研究を動機づけることを強化します。 Large Language Models (LLMs), with their advanced architectures and training on massive language datasets, contain unexplored knowledge. One method to infer this knowledge is through the use of cloze-style prompts. Typically, these prompts are manually designed because the phrasing of these prompts impacts the knowledge retrieval performance, even if the LLM encodes the desired information. In this paper, we study the impact of prompt syntax on the knowledge retrieval capacity of LLMs. We use a template-based approach to paraphrase simple prompts into prompts with a more complex grammatical structure. We then analyse the LLM performance for these structurally different but semantically equivalent prompts. Our study reveals that simple prompts work better than complex forms of sentences. The performance across the syntactical variations for simple relations (1:1) remains best, with a marginal decrease across different typologies. These results reinforce that simple prompt structures are more effective for knowledge retrieval in LLMs and motivate future research into the impact of prompt syntax on various tasks.

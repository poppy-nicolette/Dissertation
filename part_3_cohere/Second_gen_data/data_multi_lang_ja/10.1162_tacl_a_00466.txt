DOI: 10.1162/tacl_a_00466
Title: VILA: ビジュアル レイアウト グループを使用した科学 PDF からの構造化コンテンツ抽出の改善 VILA: Improving Structured Content Extraction from Scientific PDFs Using Visual Layout Groups
Abstract: PDF から構造化コンテンツを確実に抽出することは、科学論文よりも NLP にとって重要な最初のステップです。最近の研究では、基本的なレイアウト情報 (ページ上の各トークンの 2D 位置など) を言語モデルの事前トレーニングに組み込むことで、抽出精度が向上しました。パフォーマンスをさらに向上させるために、VIsual LAyout (VILA) グループ、つまりテキスト行またはテキスト ブロックを明示的にモデル化する新しいメソッドを導入します。私たちの I-VILA アプローチでは、レイアウト グループの境界を示す特別なトークンをモデル入力に挿入するだけで、マクロ F1 のトークン分類が 1.9% 向上する可能性があることを示しています。 H-VILA アプローチでは、レイアウト グループの階層エンコードにより、マクロ F1 損失が 0.8% 未満で推論時間が最大 47% 削減される可能性があることを示します。以前のレイアウトを意識したアプローチとは異なり、私たちの方法では高価な追加の事前トレーニングは必要なく、微調整のみが必要です。これにより、トレーニング コストを最大 95% 削減できることがわかります。実験は、新しく厳選された評価スイートである S2-VLUE で行われます。このスイートには、既存の自動的にラベル付けされたデータセットが統合され、19 の科学分野の多様な論文をカバーする手動注釈の新しいデータセットが含まれています。 urately extracting structured content from PDFs is a critical first step for NLP over scientific papers. Recent work has improved extraction accuracy by incorporating elementary layout information, for example, each token’s 2D position on the page, into language model pretraining. We introduce new methods that explicitly model VIsual LAyout (VILA) groups, that is, text lines or text blocks, to further improve performance. In our I-VILA approach, we show that simply inserting special tokens denoting layout group boundaries into model inputs can lead to a 1.9% Macro F1 improvement in token classification. In the H-VILA approach, we show that hierarchical encoding of layout-groups can result in up to 47% inference time reduction with less than 0.8% Macro F1 loss. Unlike prior layout-aware approaches, our methods do not require expensive additional pretraining, only fine-tuning, which we show can reduce training cost by up to 95%. Experiments are conducted on a newly curated evaluation suite, S2-VLUE, that unifies existing automatically labeled datasets and includes a new dataset of manual annotations covering diverse papers from 19 scientific disciplines.